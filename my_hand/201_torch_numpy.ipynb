{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "np_data = np.arange(6).reshape((2, 3))\n",
    "# numpy -> torch\n",
    "torch_data = torch.from_numpy(np_data)\n",
    "# torch -> numpy\n",
    "tensor2array = torch_data.numpy()\n",
    "\n",
    "print('\\n numpy array : \\n', np_data, \n",
    "      '\\n torch tensor :\\n', torch_data,\n",
    "      '\\n tensor to array : \\n', tensor2array, \n",
    "      )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " numpy array : \n",
      " [[0 1 2]\n",
      " [3 4 5]] \n",
      " torch tensor :\n",
      " tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]) \n",
      " tensor to array : \n",
      " [[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# abs\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)\n",
    "print(\"## abs ##\")\n",
    "print(f\"numpy abs :\\n{np.abs(data)} \")\n",
    "print(f\"torch abs :\\n{torch.abs(tensor)} \")\n",
    "# not working.. torch abs input must be Tensor\n",
    "print(f\"torch abs to another type : \\n{torch.abs(data)}\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "## abs ##\n",
      "numpy abs :\n",
      "[1 2 1 2] \n",
      "torch abs :\n",
      "tensor([1., 2., 1., 2.]) \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "abs(): argument 'input' (position 1) must be Tensor, not list",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-87d39248d61e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"numpy abs :\\n{np.abs(data)} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"torch abs :\\n{torch.abs(tensor)} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"torch abs to another type : \\n{torch.abs(data)}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not working.. torch abs input must be Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: abs(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# tensor object have methods for transform itself\n",
    "print(tensor.abs())\n",
    "print(tensor.sin())\n",
    "print(tensor.acos())\n",
    "print(tensor.sigmoid())\n",
    "print(tensor.mean())\n",
    "print(tensor.var())\n",
    "print(tensor.tanh())\n",
    "print(tensor.relu())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1., 2., 1., 2.])\n",
      "tensor([-0.8415, -0.9093,  0.8415,  0.9093])\n",
      "tensor([3.1416,    nan, 0.0000,    nan])\n",
      "tensor([0.2689, 0.1192, 0.7311, 0.8808])\n",
      "tensor(0.)\n",
      "tensor(3.3333)\n",
      "tensor([-0.7616, -0.9640,  0.7616,  0.9640])\n",
      "tensor([0., 0., 1., 2.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# matrix multiblication\n",
    "data = [[1, 2], [3, 4]]\n",
    "tensor = torch.FloatTensor(data)\n",
    "\n",
    "print(f\"np.matmul : \\n{np.matmul(data, data)}\")\n",
    "print(f\"numpy : \\n{torch.mm(tensor, tensor)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "np.matmul : \n",
      "[[ 7 10]\n",
      " [15 22]]\n",
      "numpy : \n",
      "tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "torch.dot(tensor1, tensor2) -> float  \n",
    "\n",
    "두 tensor의 inner product를 계산. 이때 두 tensor는 반드시 1-D vector 이어야 함."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# tensor matrix multiplication\n",
    "tensor.mm(tensor)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 7., 10.],\n",
       "        [15., 22.]])"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# tensor elementwise multiplication\n",
    "tensor*tensor"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.],\n",
       "        [ 9., 16.]])"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# tensor dot product\n",
    "torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# torch dot : can't broad casting\n",
    "data = np.array(data)\n",
    "tensor = torch.Tensor(data)\n",
    "print(\"dot\")\n",
    "print(f\"numpy.dot : \\n{data.dot(data)}\")\n",
    "# torch dot : only works for 1-dimentional tensor. \n",
    "print(f\"torch.dot : {torch.dot(tensor.dot(tensor))}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dot\n",
      "numpy.dot : \n",
      "[[ 7 10]\n",
      " [15 22]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "1D tensors expected, but got 2D and 2D tensors",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3a47b8118755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"numpy.dot : \\n{data.dot(data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# torch dot : only works for 1-dimentional tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"torch.dot : {torch.dot(tensor.dot(tensor))}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('drlnd': conda)"
  },
  "interpreter": {
   "hash": "806277ad10f6288e45e02d3e2184572cc98513f4b7f6535fc8981299374e19b2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}